{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9NE+08nt5vE06S2v2XpFo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"RdjCRTahwr5O"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_5W0MGEwhQX","executionInfo":{"status":"ok","timestamp":1724447094097,"user_tz":420,"elapsed":19388,"user":{"displayName":"Mingyuan Hua","userId":"11383044653926390732"}},"outputId":"c30ee40d-2bea-40bf-fac3-6d9b16aecdc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","path = '/content/drive/MyDrive'\n","os.chdir(path)\n","\n","!source venv_d2l/bin/activate"],"metadata":{"id":"t_HfBpbn4ok8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## !pip install d2l\n","\n","!pip install git+https://github.com/d2l-ai/d2l-en.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"bifzSedCwrA8","executionInfo":{"status":"ok","timestamp":1724447204730,"user_tz":420,"elapsed":19824,"user":{"displayName":"Mingyuan Hua","userId":"11383044653926390732"}},"outputId":"fd25844e-fecd-4dc1-acf3-070ae74ddbce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/d2l-ai/d2l-en.git\n","  Cloning https://github.com/d2l-ai/d2l-en.git to /tmp/pip-req-build-ibsfnqgx\n","  Running command git clone --filter=blob:none --quiet https://github.com/d2l-ai/d2l-en.git /tmp/pip-req-build-ibsfnqgx\n","  Resolved https://github.com/d2l-ai/d2l-en.git to commit 23d7a5aecceee57d1292c56e90cce307f183bb0a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.0.0)\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.23.5)\n","Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (3.7.2)\n","Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (0.1.6)\n","Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (2.31.0)\n","Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (2.0.3)\n","Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.5)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.5.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.4)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.5.6)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (9.4.0)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.8.2)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2024.7.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.16.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.8)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.11)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.16.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.9.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.12.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.4)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.4)\n","Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.7.2)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.1.5)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.10.0)\n","Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.10.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.3.0)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (24.0.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.20.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.1.0)\n","Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter==1.0.0->d2l==1.0.3) (2.4.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (71.0.4)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.2.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.4)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.23.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.13)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.6)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.20.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.17.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.2.2)\n"]}]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/d2l-zh'\n","os.chdir(path)"],"metadata":{"id":"9lsncuAewq-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 多GPU训练 从零开始\n","%matplotlib inline\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from d2l import torch as d2l"],"metadata":{"id":"u9SL-eYDDW3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 简单网络\n","# 把lenet那一节的代码抄了过来\n","# lenet是非常小的网络 用他来做样本网络来测试多GPU训练\n","# 这个选择也会带来问题 --\n","scale = 0.01\n","W1 = torch.randn(size=(20, 1, 3, 3)) * scale\n","b1 = torch.zeros(20)\n","W2 = torch.randn(size=(50, 20, 5, 5)) * scale\n","b2 = torch.zeros(50)\n","W3 = torch.randn(size=(800, 128)) * scale\n","b3 = torch.zeros(128)\n","W4 = torch.randn(size=(128, 10)) * scale\n","b4 = torch.zeros(10)\n","params = [W1, b1, W2, b2, W3, b3, W4, b4]\n","\n","def lenet(X, params):\n","    h1_conv = F.conv2d(input=X, weight=params[0], bias=params[1])\n","    h1_activation = F.relu(h1_conv)\n","    h1 = F.avg_pool2d(input=h1_activation, kernel_size=(2, 2), stride=(2, 2))\n","    h2_conv = F.conv2d(input=h1, weight=params[2], bias=params[3])\n","    h2_activation = F.relu(h2_conv)\n","    h2 = F.avg_pool2d(input=h2_activation, kernel_size=(2, 2), stride=(2, 2))\n","    h2 = h2.reshape(h2.shape[0], -1)\n","    h3_linear = torch.mm(h2, params[4]) + params[5]\n","    h3 = F.relu(h3_linear)\n","    y_hat = torch.mm(h3, params[6]) + params[7]\n","    return y_hat\n","\n","loss = nn.CrossEntropyLoss(reduction='none')"],"metadata":{"id":"s5asgMwlDWq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 向多个设备分发参数\n","# 如果p已经在GPU上了，保险起见，用clone才会再复制\n","def get_params(params, device):\n","    new_params = [p.clone().to(device) for p in params]\n","    for p in new_params:\n","        p.requires_grad_()\n","    return new_params\n","\n","# 开始lenet的参数全部都在CPU上的，现在我们把他放在我们的GPU0上\n","new_params = get_params(params, d2l.try_gpu(0))\n","print('b1 weight:', new_params[1])\n","print('b1 gradient:', new_params[1].grad)"],"metadata":{"id":"FLfLnUCVK4TW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# allreduce函数将所有向量相加，并将结果广播给所有GPU\n","# data是个list，里面有4个GPU的话，list有4个元素\n","# 把gpu0以外的gpu都先复制到gpu0上 to(data[0].device)，然后再相加\n","# 这样data就是所有data的求和，就把这个新的结果复制回去\n","def allreduce(data):\n","    for i in range(1, len(data)):\n","        data[0][:] += data[i].to(data[0].device)\n","    for i in range(1, len(data)):\n","        data[i] = data[0].to(data[i].device)\n","\n","data = [torch.ones((1, 2), device=d2l.try_gpu(i)) * (i + 1) for i in range(2)]\n","print('before allreduce：\\n', data[0], '\\n', data[1])\n","allreduce(data)\n","print('after allreduce：\\n', data[0], '\\n', data[1])"],"metadata":{"id":"ZhRP88IIMErM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 将一个小批量数据均匀地分布再多个GPU上\n","data = torch.arange(20).reshape(4, 5)\n","devices = [torch.device('cuda:0'), torch.device('cuda:1')]\n","# 这里使用了nn.parallel.scatter函数，data就是一个tensor，他就均匀地切开到gpu上\n","# gpu0上前两行，gpu1上后两行\n","split = nn.parallel.scatter(data, devices)\n","print('input :', data)\n","print('load into', devices)\n","print('output:', split)"],"metadata":{"id":"yuhBsafnjqgs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_batch(X, y, devices):\n","    \"\"\"将X和y拆分到多个设备上\n","    devices是GPU列表\n","    \"\"\"\n","    assert X.shape[0] == y.shape[0]\n","    return (nn.parallel.scatter(X, devices),\n","            nn.parallel.scatter(y, devices))\n","# 把样本和y都均匀地分配到GPU上"],"metadata":{"id":"c8NhI1wJjqMo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 在一个小批量上实现多GPU训练\n","# 输入小批量X,y, device_params是所有GPU上的参数，devices是我要知道用哪些GPU，lr是学习率\n","# 用split_batch函数把小批量均匀地分配到GPU上\n","def train_batch(X, y, device_params, devices, lr):\n","    X_shards, y_shards = split_batch(X, y, devices)\n","    # 对每个GPU上分别计算自己那个小批量上的样本损失\n","    # w是完整的，X_shard, y_shard是里面的一块，把x和w放入lenet里，对y求loss再求和\n","    # 返回的ls是给list，对应每个GPU上对应的损失\n","    ls = [loss(lenet(\n","        X_shard, device_W), y_shard).sum()\n","          for X_shard, y_shard, device_W in zip(\n","              X_shards, y_shards, device_params)]\n","    for l in ls: # 反向传播在每个GPU上分别执行\n","        l.backward()\n","    # 将每个GPU的所有梯度相加，并将其广播到所有GPU\n","    # i是你的层，每一层对于所有的GPU，把梯度拿出来，对他做allreduce\n","    # 这样每层的grad是替换操作，是整个小批量完整的梯度\n","    with torch.no_grad():\n","        for i in range(len(device_params[0])):\n","            allreduce(\n","                [device_params[c][i].grad for c in range(len(devices))])\n","    # 在每个GPU上分别更新模型参数\n","    for param in device_params:\n","        d2l.sgd(param, lr, X.shape[0]) # 在这里，我们使用全尺寸的小批量\n","# 这里有个问题，发现有一点串行，这就看框架在背后能不能帮你做并行了\n","# 框架做的好的话算ls和backward是可以自动并行的 mxnet和tensorflow是没问题的，pytorch有点悬\n"],"metadata":{"id":"KRZS1uhTkjaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 定义训练函数\n","def train(nums_gpus, batch_size, lr):\n","    # 创建数据iterator\n","    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n","    # 不同的就是告诉要用多少个gpu\n","    devices = [d2l.try_gpu(i) for i in range(nums_gpus)]\n","    # 将模型参数复制到num_gpus个GPU\n","    # 训练开始前把初始化的params复制到每个gpu上\n","    device_params = [get_params(params, d) for d in devices]\n","    num_epochs = 10\n","    # 后面没什么区别，画个东西，记个时\n","    animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs])\n","    timer = d2l.Timer()\n","    # 对于每个epoch，每个iterator抽个X,y\n","    for epoch in range(num_epochs):\n","        timer.start()\n","        for X, y in train_iter:\n","            # 用train_batch做一次小批量更新\n","            train_batch(X, y, device_params, devices, lr)\n","            # cuda.synchronize保证每个gpu都做完了这件事，主要为了算时间准一点\n","            torch.cuda.synchronize()\n","        timer.stop()\n","        # 在GPU0上评估模型\n","        animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(\n","            lambda x: lenet(x, device_params[0]), test_iter, devices[0]),))\n","    # 打印结果\n","    print(f'test acc：{animator.Y[0][-1]:.2f}，{timer.avg():.1f}sec/epoch，'\n","          f'on {str(devices)}')"],"metadata":{"id":"yfz78wFiuS5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 在单个GPU上运行\n","train(num_gpus=1, batch_size=256, lr=0.2)"],"metadata":{"id":"D74BZthIwLcK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 增加为2个GPU\n","train(num_gpus=2, batch_size=256, lr=0.2)"],"metadata":{"id":"j6ZEJqTTk5uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 两个的结果都是2.6 sec/epoch, 多GPU不变快或者分布式不变快这是非常常见的现象\n","# 通常的原因有\n","# 一是data读取就很慢\n","# 二是gpu增加了但是batch size没增加，之前一个gpu能处理256个样本每一次，这时候2个gpu，每个gpu只能处理128个样本，相当于batch size变低了计算性能就变低，gpu有几千个线程，\n","# 因为batch数量变小，做同样操作的效率会变低，无法多线程，没有打满gpu。遇到这种情况在增加gpu的时候，要保证每个gpu还是拿到同样多的batch size\n","# 直接*2的话会发现精度可能会变低，因为lr不变，收敛很可能会变慢，性能稍微好了一点，从2.6到2.4sec/epoch\n","# 解决测试精度的做法是把learning rate调大一点，如果batch size特别大的时候，lr也不能无限增加，测试精度也不会有原来的效果\n","# 三是这里理论上每个gpu的batch size都和原来一样，理论上性能应该比较好了，但是还是只有2.4，这里也有两个原因\n","# 1. pytorch对并行的加速不够好，裸写的写法对pytorch是不友好的\n","# 2. lenet太小了，性能确实没那么好\n","train(num_gpus=2, batch_size=256*2, lr=0.2*1.5)"],"metadata":{"id":"PFvF6WLmwt_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"-pCDD8JdEBXr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 多GPU的简洁实现\n","import torch\n","from torch import nn\n","from d2l import torch as d2l"],"metadata":{"id":"ufD0YZmJ0b4z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def resnet18(num_classes, in_channels=1):\n","    \"\"\"稍加修改的ResNet-18模型\"\"\"\n","    def resnet_block(in_channels, out_channels, num_residuals,\n","                     first_block=False):\n","        blk = []\n","        for i in range(num_residuals):\n","            if i == 0 and not first_block:\n","                blk.append(d2l.Residual(in_channels, out_channels,\n","                                        use_1x1conv=True, strides=2))\n","            else:\n","                blk.append(d2l.Residual(out_channels, out_channels))\n","        return nn.Sequential(*blk)\n","\n","    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n","    net = nn.Sequential(\n","        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU())\n","    net.add_module(\"resnet_block1\", resnet_block(\n","        64, 64, 2, first_block=True))\n","    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n","    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n","    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n","    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1,1)))\n","    net.add_module(\"fc\", nn.Sequential(nn.Flatten(),\n","                                       nn.Linear(512, num_classes)))\n","    return net"],"metadata":{"id":"A0x1TJQIwq8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = resnet18(10)\n","# 获取GPU列表\n","devices = d2l.try_all_gpus()\n","# 我们将在训练代码实现中初始化网络"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"IZuAji76wq5u","executionInfo":{"status":"error","timestamp":1723674795846,"user_tz":420,"elapsed":1271,"user":{"displayName":"Mingyuan Hua","userId":"11383044653926390732"}},"outputId":"f8e2b133-fb42-4e4a-9a83-f20ac6622559"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"Residual.__init__() got multiple values for argument 'use_1x1conv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-0d336707e69e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 获取GPU列表\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtry_all_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 我们将在训练代码实现中初始化网络\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-a0037c34908a>\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(num_classes, in_channels)\u001b[0m\n\u001b[1;32m     19\u001b[0m     net.add_module(\"resnet_block1\", resnet_block(\n\u001b[1;32m     20\u001b[0m         64, 64, 2, first_block=True))\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resnet_block2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resnet_block3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resnet_block4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-a0037c34908a>\u001b[0m in \u001b[0;36mresnet_block\u001b[0;34m(in_channels, out_channels, num_residuals, first_block)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_residuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 blk.append(d2l.Residual(in_channels, out_channels,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                         use_1x1conv=True, strides=2))\n\u001b[1;32m     10\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Residual.__init__() got multiple values for argument 'use_1x1conv'"]}]},{"cell_type":"code","source":["def train(net, num_gpus, batch_size, lr):\n","    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n","    devices = [d2l.try_gpu(i) for i in range(num_gpus)]\n","    def init_weights(m):\n","        if type(m) in [nn.Linear, nn.Conv2d]:\n","            nn.init.xavier_uniform_(m.weight, std=0.01)\n","    net.apply(init_weights)\n","    # 在多个GPU上设置模型\n","    net = nn.DataParallel(net, device_ids=devices)\n","    trainer = torch.optim.SGD(net.parameters(), lr)\n","    loss = nn.CrossEntropyLoss()\n","    timer, num_epochs = d2l.Timer(), 10\n","    animator = d2l.Animator('epoch', 'test acc', xlim=[1, num_epochs])\n","    for epoch in range(num_epochs):\n","        net.train()\n","        timer.start()\n","        for X, y in train_iter:\n","            trainer.zero_grad()\n","            X, y = X.to(devices[0]), y.to(devices[0])\n","            l = loss(net(X), y)\n","            l.backward()\n","            trainer.step()\n","        timer.stop()\n","        animator.add(epoch + 1, (d2l.evaluate_accuracy_gpu(net, test_iter),))\n","    print(f'测试精度：{animator.Y[0][-1]:.2f}，{timer.avg():.1f}秒/轮，'\n","          f'在{str(devices)}')"],"metadata":{"id":"so1agnr9wq0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(net, num_gpus=1, batch_size=256, lr=0.1)"],"metadata":{"id":"pAU6SCvYwqlx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(net, num_gpus=2, batch_size=512, lr=0.2)"],"metadata":{"id":"XUc4Evl74BTV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"408XLA694BGE"},"execution_count":null,"outputs":[]}]}