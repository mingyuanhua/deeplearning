{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOu9GCp5DsukRazY7RAgCbs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npd9IVR-EbQa","executionInfo":{"status":"ok","timestamp":1711562566637,"user_tz":420,"elapsed":18297,"user":{"displayName":"Mingyuan Hua","userId":"11383044653926390732"}},"outputId":"f98f6314-6cd5-481b-8f87-08a5707c5870"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","path = '/content/drive/MyDrive'\n","os.chdir(path)\n","\n","!source venv_d2l/bin/activate"],"metadata":{"id":"fmJmim0EFMce","executionInfo":{"status":"ok","timestamp":1711564097553,"user_tz":420,"elapsed":11,"user":{"displayName":"Mingyuan Hua","userId":"11383044653926390732"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install \"mxnet<2.0.0\""],"metadata":{"id":"yLs-WYodFYdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install autogluon"],"metadata":{"id":"LBBLvelnFbt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/d2l-zh'\n","os.chdir(path)"],"metadata":{"id":"NotKqeJ_K5ED","executionInfo":{"status":"ok","timestamp":1711564179913,"user_tz":420,"elapsed":243,"user":{"displayName":"Mingyuan Hua","userId":"11383044653926390732"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Auto ML training\n","from autogluon.tabular import TabularDataset, TabularPredictor\n","import numpy as np\n","\n","train_data = TabularDataset('train.csv')\n","id, label = 'Id', 'Sold Price'\n","# 数据预处理\n","large_val_cols = ['Lot', 'Total interior livable area', 'Tax assessed value',\n","                  'Annual tax amount', 'Listed Price', 'Last Sold Price']\n","for c in large_val_cols + [label]:\n","    train_data[c] = np.log(train_data[c]+1)\n","# predictor = TabularPredictor(label=label).fit(train_data.drop(columns=[id]))\n","# 更好的模型 需要GPU才跑得动\n","predictor = TabularPredictor(label=label).fit(train_data.drop(columns=[id]), hyperparameters='multimodal', num_stack_levels=1, num_bag_folds=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msESveIQE-Hp","outputId":"d5b3c64c-cbaa-4779-9ea1-38c2778ee1fa"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20240327_183426\"\n","No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n","\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n","\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n","\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n","\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n","\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n","Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (47439 samples, 107.1 MB).\n","\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n","Beginning AutoGluon training ...\n","AutoGluon will save models to \"AutogluonModels/ag-20240327_183426\"\n","=================== System Info ===================\n","AutoGluon Version:  1.0.0\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n","CPU Count:          2\n","Memory Avail:       11.20 GB / 12.67 GB (88.4%)\n","Disk Space Avail:   9.38 GB / 15.00 GB (62.5%)\n","\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n","\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n","===================================================\n","Train Data Rows:    47439\n","Train Data Columns: 39\n","Label Column:       Sold Price\n","AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n","\tLabel info (max, min, mean, stddev): (18.31532023940565, 11.51792295668052, 13.73905, 0.79676)\n","\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n","Problem Type:       regression\n","Preprocessing data ...\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    11546.87 MB\n","\tTrain Data (Original)  Memory Usage: 101.78 MB (0.9% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\t\tFitting IdentityFeatureGenerator...\n","\t\t\tFitting RenameFeatureGenerator...\n","\t\tFitting CategoryFeatureGenerator...\n","\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n","\t\tFitting DatetimeFeatureGenerator...\n","\t\tFitting TextSpecialFeatureGenerator...\n","\t\t\tFitting BinnedFeatureGenerator...\n","\t\t\tFitting DropDuplicatesFeatureGenerator...\n","\t\tFitting TextNgramFeatureGenerator...\n","\t\t\tFitting CountVectorizer for text features: ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', 'Bedrooms', 'Elementary School', 'Middle School', 'High School', 'Flooring', 'Heating features', 'Cooling features', 'Appliances included', 'Laundry features', 'Parking features']\n","\t\t\tCountVectorizer fit with vocabulary size = 10000\n","\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n","\t\tReducing Vectorizer vocab size from 10000 to 5928 to avoid OOM error\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', [])                      : 17 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n","\t\t('int', [])                        :  1 | ['Zip']\n","\t\t('object', [])                     :  4 | ['Type', 'Region', 'City', 'State']\n","\t\t('object', ['datetime_as_object']) :  2 | ['Listed On', 'Last Sold On']\n","\t\t('object', ['text'])               : 15 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('category', [])                    :    3 | ['Type', 'Region', 'City']\n","\t\t('category', ['text_as_category'])  :   15 | ['Address', 'Summary', 'Heating', 'Cooling', 'Parking', ...]\n","\t\t('float', [])                       :   17 | ['Year built', 'Lot', 'Bathrooms', 'Full bathrooms', 'Total interior livable area', ...]\n","\t\t('int', [])                         :    1 | ['Zip']\n","\t\t('int', ['binned', 'text_special']) :  180 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n","\t\t('int', ['bool'])                   :    1 | ['State']\n","\t\t('int', ['datetime_as_int'])        :   10 | ['Listed On', 'Listed On.year', 'Listed On.month', 'Listed On.day', 'Listed On.dayofweek', ...]\n","\t\t('int', ['text_ngram'])             : 5387 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 in', '__nlp__.000 in august', '__nlp__.000 in december', ...]\n","\t\t('object', ['text'])                :   15 | ['Address_raw_text', 'Summary_raw_text', 'Heating_raw_text', 'Cooling_raw_text', 'Parking_raw_text', ...]\n","\t145.3s = Fit runtime\n","\t39 features in original data used to generate 5629 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 590.52 MB (5.0% of available memory)\n","Data preprocessing and feature engineering runtime = 150.98s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n","\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': {},\n","\t'GBM': [{}, {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge'],\n","\t'CAT': {},\n","\t'XGB': {},\n","\t'AG_AUTOMM': {},\n","\t'VW': {},\n","}\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\n","Fitting 8 L1 models ...\n","Fitting model: LightGBM_BAG_L1 ...\n","\tMemory not enough to fit 5 folds in parallel. Will train 1 folds in parallel instead (Estimated 42.79% memory usage per fold, 42.79%/80.00% total).\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=1, gpus=0, memory=42.79%)\n","\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n","\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","test_data = TabularDataset('test.csv')\n","preds = predictor.predict(test_data.drop(columns=[id]))\n","submission = pd.DataFrame({id:test_data[id], label:preds})\n","submission.to_csv('submission.csv', index=False)"],"metadata":{"id":"fjG_UU0nFJ2n"},"execution_count":null,"outputs":[]}]}